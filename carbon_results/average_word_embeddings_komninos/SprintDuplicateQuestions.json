{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "mteb_dataset_name": "SprintDuplicateQuestions",
  "mteb_version": "1.2.0",
  "test": {
    "co2_emissions": 6.425397635899963e-05,
    "cos_sim": {
      "accuracy": 0.9964653465346535,
      "accuracy_threshold": 0.8894756436347961,
      "ap": 0.8555090397855646,
      "f1": 0.8103896103896104,
      "f1_threshold": 0.8806538581848145,
      "precision": 0.8432432432432433,
      "recall": 0.78
    },
    "dot": {
      "accuracy": 0.9903762376237624,
      "accuracy_threshold": 10.757030487060547,
      "ap": 0.2521099059479158,
      "f1": 0.3176525384257103,
      "f1_threshold": 8.506962776184082,
      "precision": 0.2972972972972973,
      "recall": 0.341
    },
    "euclidean": {
      "accuracy": 0.9962673267326733,
      "accuracy_threshold": 1.3987889289855957,
      "ap": 0.8249439029969332,
      "f1": 0.7936507936507937,
      "f1_threshold": 1.3987889289855957,
      "precision": 0.8766626360338573,
      "recall": 0.725
    },
    "evaluation_time": 1.8,
    "manhattan": {
      "accuracy": 0.9962574257425743,
      "accuracy_threshold": 19.19061851501465,
      "ap": 0.8248883861912972,
      "f1": 0.7923076923076923,
      "f1_threshold": 19.19061851501465,
      "precision": 0.8792682926829268,
      "recall": 0.721
    },
    "max": {
      "accuracy": 0.9964653465346535,
      "ap": 0.8555090397855646,
      "f1": 0.8103896103896104
    }
  }
}